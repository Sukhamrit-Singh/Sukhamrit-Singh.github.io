<!DOCTYPE html>
<html>
<head>
    <title>Project 4 - CS180</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;
            line-height: 1.8;
            color: #e0e0e0;
            background: #0a0a0a;
            min-height: 100vh;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 60px 80px;
        }

        h1 {
            font-size: 2.5em;
            font-weight: 300;
            letter-spacing: -1px;
            color: #ffffff;
            margin-bottom: 8px;
        }

        .subtitle {
            font-size: 1em;
            color: #808080;
            margin-bottom: 60px;
            font-weight: 400;
        }

        .author {
            color: #606060;
            margin: 10px 0;
            font-size: 1em;
        }

        h2 {
            color: #ffffff;
            font-size: 1.8em;
            font-weight: 300;
            margin: 80px 0 40px;
            letter-spacing: -0.5px;
        }

        h3 {
            color: #c0c0c0;
            font-size: 1.3em;
            font-weight: 300;
            margin: 40px 0 20px;
        }

        p {
            color: #a0a0a0;
            margin-bottom: 20px;
            line-height: 1.8;
        }

        ul, ol {
            color: #a0a0a0;
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 8px;
        }

        code {
            background: #1a1a1a;
            color: #80ff80;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: inherit;
        }

        pre {
            background: #1a1a1a;
            color: #80ff80;
            padding: 20px;
            border-radius: 4px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: inherit;
        }

        .image-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .image-wrapper {
            margin-bottom: 20px;
        }

        .image-container {
            position: relative;
            overflow: hidden;
            background: #1a1a1a;
            border-radius: 4px;
            transition: transform 0.2s ease;
        }

        .image-container:hover {
            transform: scale(1.02);
        }

        .image-container img {
            width: 100%;
            height: auto;
            display: block;
            opacity: 0.9;
            transition: opacity 0.2s ease;
        }

        .image-container:hover img {
            opacity: 1;
        }

        .image-caption {
            color: #ffffff;
            font-size: 0.95em;
            margin-top: 10px;
            text-align: center;
        }

        .offset-info {
            font-size: 0.85em;
            color: #606060;
            margin-top: 4px;
            text-align: center;
        }

        .comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 40px 0;
        }

        .comparison-item {
            text-align: center;
        }

        .comparison-item img {
            width: 100%;
            border-radius: 4px;
            margin-bottom: 10px;
        }

        .comparison-label {
            color: #808080;
            font-size: 0.9em;
        }

        .algorithm-box {
            background: #1a1a1a;
            border-left: 3px solid #404040;
            padding: 20px;
            margin: 30px 0;
            border-radius: 4px;
        }

        .highlight {
            background: #1a1a1a;
            border-left: 3px solid #ffff00;
            padding: 20px;
            margin: 30px 0;
            border-radius: 4px;
        }

        .results-table {
            width: 100%;
            border-collapse: collapse;
            margin: 40px 0;
        }

        .results-table th {
            background: #1a1a1a;
            color: #ffffff;
            padding: 12px;
            text-align: left;
            font-weight: 400;
        }

        .results-table td {
            padding: 10px;
            border-bottom: 1px solid #2a2a2a;
            color: #a0a0a0;
        }

        .results-table tr:hover {
            background: #151515;
        }

        .back-button {
            position: fixed;
            top: 20px;
            left: 20px;
            background: #1a1a1a;
            border: 1px solid #404040;
            color: #808080;
            padding: 8px 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 8px;
            text-decoration: none;
            transition: all 0.2s ease;
            z-index: 1000;
            font-size: 14px;
        }
        
        .back-button:hover {
            background: #2a2a2a;
            color: #ffffff;
            border-color: #606060;
        }

        .triple-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 20px;
            margin: 40px 0;
        }

        .quad-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            grid-template-rows: 1fr 1fr;
            gap: 20px;
            margin: 40px 0;
        }

        .training-progression {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 40px 0;
        }

        .video-container {
            display: flex;
            justify-content: center;
            margin: 40px 0;
        }

        .video-container video {
            max-width: 100%;
            border-radius: 4px;
        }

        .psnr-info {
            background: #1a1a1a;
            border-left: 3px solid #40ff40;
            padding: 20px;
            margin: 30px 0;
            border-radius: 4px;
        }

        .large-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 40px 0;
            max-width: 80%;
            margin-left: auto;
            margin-right: auto;
        }

        .frustum-container {
            background: #f0f0f0;
            border-radius: 4px;
            padding: 20px;
            aspect-ratio: 1920 / 934;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .frustum-container img {
            width: 100%;
            height: 100%;
            object-fit: contain;
        }

        .ray-frustum-container img {
            width: 120%;
            height: 120%;
            object-fit: contain;
            transform: translateY(8%);
        }
        
        .ray-zoom-container img {
            width: 150%;
            height: 150%;
            object-fit: contain;
            transform: translateY(10%);
        }
        
        .frustum-shift-right img {
            transform: translateX(10%);
        }
        
        .frustum-shift-down img {
            transform: translateY(5%) translateX(-8%);
        }

        @media (max-width: 768px) {
            .container {
                padding: 40px;
            }
            
            .image-grid {
                grid-template-columns: 1fr;
            }
            
            .comparison {
                grid-template-columns: 1fr;
            }

            .triple-comparison {
                grid-template-columns: 1fr;
            }

            .quad-grid {
                grid-template-columns: 1fr;
                grid-template-rows: auto;
            }
        }

        .equation {
            background: transparent;
            color: #80ff80;
            padding: 12px 6px;
            border-radius: 4px;
            overflow-x: auto;
            margin: 6px 0;
            font-family: inherit;
            white-space: nowrap;
        }

        .matrix-block {
            display: flex;
            gap: 20px;
            align-items: center;
            justify-content: center;
            flex-wrap: wrap;
            margin: 18px 0;
        }

        .architecture-diagram {
            background: #1a1a1a;
            border-radius: 8px;
            padding: 30px;
            margin: 30px 0;
            overflow-x: auto;
        }

        .layer {
            display: inline-block;
            background: #2a2a2a;
            border: 2px solid #404040;
            border-radius: 6px;
            padding: 15px 10px;
            margin: 5px;
            text-align: center;
            min-width: 80px;
            position: relative;
            vertical-align: middle;
        }

        .layer.input {
            background: #1a4a1a;
            border-color: #40ff40;
            color: #40ff40;
        }

        .layer.hidden {
            background: #1a1a4a;
            border-color: #4080ff;
            color: #4080ff;
        }

        .layer.output {
            background: #4a1a1a;
            border-color: #ff4040;
            color: #ff4040;
        }

        .layer.pe {
            background: #4a4a1a;
            border-color: #ffff40;
            color: #ffff40;
        }

        .layer.skip {
            background: #4a1a4a;
            border-color: #ff40ff;
            color: #ff40ff;
        }

        .arrow {
            display: inline-block;
            margin: 0 10px;
            color: #808080;
            font-size: 20px;
            vertical-align: middle;
        }

        .layer-label {
            font-size: 0.85em;
            font-weight: bold;
        }

        .layer-dim {
            font-size: 0.7em;
            color: #c0c0c0;
            margin-top: 3px;
        }

        .activation {
            font-size: 0.6em;
            color: #a0a0a0;
            margin-top: 2px;
            font-style: italic;
        }

        .architecture-flow {
            display: flex;
            align-items: center;
            justify-content: center;
            flex-wrap: wrap;
            gap: 10px;
            margin: 20px 0;
        }

        .branch {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 10px;
        }

        .concat {
            background: #2a4a2a;
            border: 2px solid #60ff60;
            color: #60ff60;
            border-radius: 6px;
            padding: 8px 12px;
            font-size: 0.8em;
        }

        .nerf-architecture {
            display: flex;
            flex-direction: column;
            gap: 20px;
            background: #1a1a1a;
            padding: 30px;
            border-radius: 8px;
            margin: 30px 0;
        }

        .nerf-flow {
            display: flex;
            align-items: center;
            justify-content: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 15px 0;
        }

        .nerf-input-section {
            border: 1px dashed #404040;
            padding: 20px;
            border-radius: 6px;
            margin-bottom: 20px;
        }

        .skip-connection {
            position: relative;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .skip-arrow {
            position: absolute;
            top: -30px;
            left: 50%;
            transform: translateX(-50%);
            color: #ff40ff;
            font-size: 12px;
            white-space: nowrap;
        }

        /* Ensure MathJax renders in regular text color */
        .MathJax, .MathJax * {
            color: #ffffff !important;
        }
        
        /* For inline math */
        .MathJax_Display {
            color: #ffffff !important;
        }

        /* For any green math text */
        mjx-math, mjx-math * {
            color: #ffffff !important;
        }

        /* Print styles for PDF export */
        @media print {
            body {
                background: white !important;
                color: black !important;
            }
            
            .MathJax, .MathJax * {
                color: black !important;
            }
            
            mjx-math, mjx-math * {
                color: black !important;
            }
            
            h1, h2, h3, h4 {
                color: black !important;
            }
            
            p, li, div {
                color: black !important;
            }
            
            .comparison-label {
                color: black !important;
            }
        }
    </style>
    <script>
        window.MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
            svg: { fontCache: 'global' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
    <a href="./index.html" class="back-button" title="Back to portfolio">
        <span style="font-size: 14px;">../</span>
    </a>
    
    <div class="container">
        <div style="margin-bottom: 60px;">
            <h1 style="margin-bottom: 20px;">proj4/</h1>
            <div style="margin-left: 40px;">
                <div style="margin: 8px 0;">
                    <a href="#overview" style="color: #808080; text-decoration: none; transition: color 0.2s ease;">
                        <span style="color: #404040;">├── </span>
                        <span style="color: #ffffff;">overview/</span>
                        <span style="color: #606060; margin-left: 8px;">Neural Radiance Fields</span>
                    </a>
                </div>
                <div style="margin: 8px 0;">
                    <a href="#part0" style="color: #808080; text-decoration: none; transition: color 0.2s ease;">
                        <span style="color: #404040;">├── </span>
                        <span style="color: #ffffff;">part0/</span>
                        <span style="color: #606060; margin-left: 8px;">Camera Calibration and 3D Scanning</span>
                    </a>
                </div>
                <div style="margin: 8px 0;">
                    <a href="#part1" style="color: #808080; text-decoration: none; transition: color 0.2s ease;">
                        <span style="color: #404040;">├── </span>
                        <span style="color: #ffffff;">part1/</span>
                        <span style="color: #606060; margin-left: 8px;">2D Neural Field</span>
                    </a>
                </div>
                <div style="margin: 8px 0;">
                    <a href="#part2" style="color: #808080; text-decoration: none; transition: color 0.2s ease;">
                        <span style="color: #404040;">├── </span>
                        <span style="color: #ffffff;">part2/</span>
                        <span style="color: #606060; margin-left: 8px;">3D Neural Radiance Field</span>
                    </a>
                </div>
                <div style="margin: 8px 0;">
                    <a href="#part2_6" style="color: #808080; text-decoration: none; transition: color 0.2s ease;">
                        <span style="color: #404040;">└── </span>
                        <span style="color: #ffffff;">part2.6/</span>
                        <span style="color: #606060; margin-left: 8px;">Own Data NeRF</span>
                    </a>
                </div>
            </div>
        </div>

        <h1 style="font-size: 2.5em; margin-bottom: 10px;">Neural Radiance Fields!</h1>
        <div style="color: #808080; margin-bottom: 40px; font-size: 1em;">CS180 Project 4: Neural Radiance Fields and Volume Rendering</div>

        <h2 id="overview">Overview</h2>
        <p>
            This project explores Neural Radiance Fields (NeRF), a cutting-edge technique for 3D scene representation 
            and view synthesis. We implement neural networks that learn implicit representations of 3D scenes 
            from multi-view images, enabling photorealistic view synthesis. The project spans from 2D neural 
            fields to full 3D NeRF implementation, including camera calibration, volume rendering, and training on 
            both synthetic and real-world data.
        </p>

        <div style="background: linear-gradient(90deg, #1a1a1a 0%, transparent 100%); padding: 20px; margin: 60px -20px 40px; border-left: 3px solid #ff4040;">
            <h2 id="part0" style="margin: 0; color: #ff4040;">Part 0: Camera Calibration and 3D Scanning</h2>
            <div style="color: #808080; font-size: 0.9em; margin-top: 5px;">ArUco-based camera calibration and pose estimation</div>
        </div>

        <p>
            For this section, I calibrated my camera using ArUco tags and captured multi-view images of a chosen object. 
            The calibration process involved capturing 30-50 images of ArUco calibration tags, extracting corner coordinates, 
            and using OpenCV's camera calibration to compute intrinsic parameters and distortion coefficients.
        </p>


        <p>
            After calibration, I captured images of my chosen object (a small figurine) alongside a single ArUco tag, 
            then used the calibrated camera parameters to estimate camera poses via solvePnP. The final step involved 
            undistorting images and packaging everything into a dataset format compatible with NeRF training.
        </p>

        <h3>Sample Images from Data Capture</h3>
        <p>Examples of captured images showing the object alongside the ArUco tag for pose estimation:</p>

        <div class="training-progression">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part0_content/IMG_2311 Large.jpeg" alt="Sample Image 1">
                </div>
                <div class="comparison-label">Captured Image 1</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part0_content/IMG_2324 Large.jpeg" alt="Sample Image 2">
                </div>
                <div class="comparison-label">Captured Image 2</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part0_content/IMG_2346 Large.jpeg" alt="Sample Image 3">
                </div>
                <div class="comparison-label">Captured Image 3</div>
            </div>
        </div>

        <h3>Camera Frustum Visualizations</h3>
        <p>Screenshots of the camera frustums visualization in Viser, showing the estimated camera poses:</p>

        <div class="comparison">
            <div class="comparison-item">
                <div class="image-container frustum-container">
                    <img src="proj4/part0_content/vaja_frustum1.png" alt="Camera Frustums 1">
                </div>
                <div class="comparison-label">Camera Frustums Visualization - View 1</div>
            </div>
            <div class="comparison-item">
                <div class="image-container frustum-container">
                    <img src="proj4/part0_content/vaja_frustum2.png" alt="Camera Frustums 2">
                </div>
                <div class="comparison-label">Camera Frustums Visualization - View 2</div>
            </div>
        </div>

        <div class="comparison">
            <div class="comparison-item">
                <div class="image-container frustum-container frustum-shift-right">
                    <img src="proj4/part0_content/vaja_frustum3.png" alt="Camera Frustums 3">
                </div>
                <div class="comparison-label">Camera Frustums Visualization - View 3</div>
            </div>
            <div class="comparison-item">
                <div class="image-container frustum-container frustum-shift-down">
                    <img src="proj4/part0_content/vaja_frustum4.png" alt="Camera Frustums 4">
                </div>
                <div class="comparison-label">Camera Frustums Visualization - View 4</div>
            </div>
        </div>

        <div style="background: linear-gradient(90deg, #1a1a1a 0%, transparent 100%); padding: 20px; margin: 60px -20px 40px; border-left: 3px solid #40ff40;">
            <h2 id="part1" style="margin: 0; color: #40ff40;">Part 1: 2D Neural Field</h2>
            <div style="color: #808080; font-size: 0.9em; margin-top: 5px;">Fitting neural networks to represent 2D images</div>
        </div>

        <p>
            Before implementing 3D NeRF, I started with a simpler 2D version to understand the fundamentals. 
            I created a Multilayer Perceptron (MLP) with Sinusoidal Positional Encoding that takes 2D pixel 
            coordinates as input and outputs RGB color values. The network was trained to fit entire images 
            by optimizing pixel-wise color predictions.
        </p>

        <h3>2D Neural Field Architecture</h3>
        
        <div style="text-align: center; margin: 30px auto; max-width: 75%;">
            <img src="proj4/2d_nn_design.jpg" alt="2D Neural Field Architecture" style="width: 100%; height: auto; border-radius: 4px;">
        </div>

        <div class="algorithm-box">
            <h4>Network Architecture Details:</h4>
            <ul>
                <li><strong>Number of Layers:</strong> 4-layer MLP (3 hidden layers + output layer)</li>
                <li><strong>Width:</strong> 256 hidden units per layer</li>
                <li><strong>Input Dimension:</strong> $L \times 2 \times 2 + 2 = 42$ for $L=10$ positional encoding</li>
                <li><strong>Output Dimension:</strong> 3 (RGB color values)</li>
                <li><strong>Activation Functions:</strong> ReLU for hidden layers, Sigmoid for output</li>
                <li><strong>Positional Encoding:</strong> Sinusoidal PE with $L=10$ frequency levels</li>
                <li><strong>Learning Rate:</strong> $1 \times 10^{-2}$ with Adam optimizer</li>
                <li><strong>Batch Size:</strong> 10,000 pixels sampled per epoch</li>
            </ul>
        </div>

        <h3>Training Progression</h3>
        <p>Below shows the training progression for both the provided fox image and my own Messi image:</p>

        <h4>Fox Image Training</h4>
        <div class="training-progression">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/fox/reconstruction_epoch_0.png" alt="Fox Epoch 0">
                </div>
                <div class="comparison-label">Epoch 0</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/fox/reconstruction_epoch_100.png" alt="Fox Epoch 100">
                </div>
                <div class="comparison-label">Epoch 100</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/fox/reconstruction_epoch_400.png" alt="Fox Epoch 400">
                </div>
                <div class="comparison-label">Epoch 400</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/fox/reconstruction_epoch_1600.png" alt="Fox Epoch 1600">
                </div>
                <div class="comparison-label">Epoch 1600</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/fox/reconstruction_epoch_2999.png" alt="Fox Epoch 2999">
                </div>
                <div class="comparison-label">Epoch 2999</div>
            </div>
        </div>

        <div class="comparison">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/part1_image.jpg" alt="Original Fox Image">
                </div>
                <div class="comparison-label">Original Fox Image</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/fox/reconstruction_epoch_2999.png" alt="Fox Final Reconstruction">
                </div>
                <div class="comparison-label">Neural Field Reconstruction</div>
            </div>
        </div>

        <h4>Messi Image Training</h4>
        <div class="training-progression">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/messi/reconstruction_epoch_0.png" alt="Messi Epoch 0">
                </div>
                <div class="comparison-label">Epoch 0</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/messi/reconstruction_epoch_100.png" alt="Messi Epoch 100">
                </div>
                <div class="comparison-label">Epoch 100</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/messi/reconstruction_epoch_400.png" alt="Messi Epoch 400">
                </div>
                <div class="comparison-label">Epoch 400</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/messi/reconstruction_epoch_1600.png" alt="Messi Epoch 1600">
                </div>
                <div class="comparison-label">Epoch 1600</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/messi/reconstruction_epoch_2999.png" alt="Messi Epoch 2999">
                </div>
                <div class="comparison-label">Epoch 2999</div>
            </div>
        </div>

        <div class="comparison">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/messi.jpg" alt="Original Messi Image">
                </div>
                <div class="comparison-label">Original Messi Image</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/training_progressions/messi/reconstruction_epoch_2999.png" alt="Messi Final Reconstruction">
                </div>
                <div class="comparison-label">Neural Field Reconstruction</div>
            </div>
        </div>

        <h3>Hyperparameter Analysis</h3>
        <p>I experimented with different positional encoding frequencies (L) and network widths:</p>

        <div class="quad-grid">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/final_results/reconstruction_L2_W64.png" alt="L2 W64">
                </div>
                <div class="comparison-label">$L=2$, Width=64</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/final_results/reconstruction_L2_W256.png" alt="L2 W256">
                </div>
                <div class="comparison-label">$L=2$, Width=256</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/final_results/reconstruction_L10_W64.png" alt="L10 W64">
                </div>
                <div class="comparison-label">$L=10$, Width=64</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/final_results/reconstruction_L10_W256.png" alt="L10 W256">
                </div>
                <div class="comparison-label">$L=10$, Width=256</div>
            </div>
        </div>

        <p>
            As expected, higher positional encoding frequencies ($L=10$) capture fine details better than lower frequencies ($L=2$). 
            Similarly, wider networks (256 units) produce smoother reconstructions compared to narrower ones (64 units).
        </p>

        <h3>Training Metrics</h3>
        
        <h4>Fox Image Training Curves</h4>
        <div class="comparison">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/psnr_curve.png" alt="Fox PSNR Curve">
                </div>
                <div class="comparison-label">PSNR Training Curve (Fox Image)</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/loss_curve.png" alt="Fox Loss Curve">
                </div>
                <div class="comparison-label">Loss Training Curve (Fox Image)</div>
            </div>
        </div>

        <h4>Messi Image Training Curves</h4>
        <div class="comparison">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/messi_psnr_curve.png" alt="Messi PSNR Curve">
                </div>
                <div class="comparison-label">PSNR Training Curve (Messi Image)</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part1_content/messi_loss_curve.png" alt="Messi Loss Curve">
                </div>
                <div class="comparison-label">Loss Training Curve (Messi Image)</div>
            </div>
        </div>

        <div style="background: linear-gradient(90deg, #1a1a1a 0%, transparent 100%); padding: 20px; margin: 60px -20px 40px; border-left: 3px solid #4080ff;">
            <h2 id="part2" style="margin: 0; color: #4080ff;">Part 2: Neural Radiance Field from Multi-view Images</h2>
            <div style="color: #808080; font-size: 0.9em; margin-top: 5px;">Full 3D NeRF implementation with volume rendering</div>
        </div>

        <p>
            Building on the 2D neural field foundation, I implemented a full Neural Radiance Field that represents 
            3D scenes from multi-view images using inverse rendering from calibrated cameras.
        </p>

        <h3>Part 2.1: Create Rays from Cameras</h3>
        <p>
            I implemented three core coordinate transformations to generate camera rays. First, I used 4×4 transformation matrices to convert points from camera space to world coordinates: $\mathbf{x}_w = \mathbf{R} \mathbf{x}_c + \mathbf{t}$. Then I inverted the camera intrinsic matrix to convert pixel coordinates to 3D camera coordinates: $\mathbf{x}_c = K^{-1} \begin{bmatrix} u \\ v \\ 1 \end{bmatrix}$. Finally, I generated rays by computing the origin as the camera position $\mathbf{o} = \mathbf{t}$ and the direction as the normalized vector from camera center through each pixel.
        </p>

        <h3>Part 2.2: Sampling</h3>
        <p>
            I implemented random ray sampling from multi-view images, adding 0.5 to UV coordinates to sample from pixel centers rather than corners. For each ray, I uniformly sampled 64 points between near and far planes by dividing the ray into equal intervals. During training, I added random perturbations $t_i = t_i + \mathcal{U}(0, \Delta t)$ to sample positions to prevent overfitting and ensure the model explores all locations along each ray.
        </p>

        <h3>Part 2.3: Putting the Dataloading All Together</h3>
        <p>
            I created a unified $\texttt{RaysData}$ class that precomputes ray origins and directions for all training images, then efficiently samples 10,000 random rays per iteration. This dataloader returns ray origins, directions, and corresponding ground truth RGB colors for batch training. I verified the implementation by visualizing camera frustums, rays, and 3D sample points using Viser.
        </p>

        <div class="comparison">
            <div class="comparison-item">
                <div class="image-container frustum-container ray-zoom-container">
                    <img src="proj4/part2_content/visualizations_rays/lego_render1.png" alt="Rays Visualization 1">
                </div>
                <div class="comparison-label">Camera Frustums and Rays - View 1</div>
            </div>
            <div class="comparison-item">
                <div class="image-container frustum-container ray-zoom-container">
                    <img src="proj4/part2_content/visualizations_rays/lego_render2.png" alt="Rays Visualization 2">
                </div>
                <div class="comparison-label">Camera Frustums and Rays - View 2</div>
            </div>
        </div>
        
        <div style="display: flex; justify-content: center; margin: 40px 0;">
            <div style="text-align: center; width: 50%;">
                <div class="image-container frustum-container ray-frustum-container">
                    <img src="proj4/part2_content/visualizations_rays/lego_render3.png" alt="Rays Visualization 3">
                </div>
                <div class="comparison-label">Camera Frustums and Rays - View 3</div>
            </div>
        </div>

        <h3>Part 2.4: Neural Radiance Field</h3>
        <p>
            I built an 8-layer MLP that takes positionally-encoded 3D coordinates ($L=10$) and view directions ($L=4$) as input. The network uses skip connections at layer 5 and has separate heads for density prediction (with ReLU) and view-dependent color prediction (with Sigmoid). There's also a skip connection for the RGB branch where the view directions ($\mathbf{r}_d$) are concatenated at the second RGB fully connected layer. This architecture allows the model to capture both geometric structure and view-dependent appearance effects.
        </p>

        <h3>3D Neural Radiance Field Architecture</h3>
        
        <div style="text-align: center; margin: 30px auto; max-width: 75%;">
            <img src="proj4/3d_nn_design.png" alt="3D Neural Radiance Field Architecture" style="width: 100%; height: auto; border-radius: 4px;">
        </div>


        <h3>Part 2.5: Volume Rendering</h3>
        <p>
            I implemented the discrete volume rendering equation to composite colors and densities along rays into final pixel colors: $C(\mathbf{r}) = \sum_{i=1}^{N} T_i \alpha_i \mathbf{c}_i$. The function computes alpha values $\alpha_i = 1 - \exp(-\sigma_i \delta_i)$ and transmittance $T_i = \exp(-\sum_{j=1}^{i-1} \sigma_j \delta_j)$ using cumulative sums for proper alpha compositing. My implementation passed the provided torch.allclose() test, ensuring correct mathematical computation of the rendering integral.
        </p>

        <h3>Training Progression</h3>
        <p>Training progression showing the NeRF learning to represent the Lego scene. The model was trained for 2000 epochs using Adam optimizer with learning rate $5 \times 10^{-4}$, sampling 10,000 rays per iteration and 64 points per ray. Near and far planes were set to $z_{\text{near}}=2.0$ and $z_{\text{far}}=6.0$ respectively. The network uses positional encoding with $L=10$ frequencies for 3D coordinates and $L=4$ frequencies for view directions, with 256 hidden units per layer.</p>

        <div class="training-progression">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2_content/training_progression/lego_200_epoch_render.png" alt="200 Epochs">
                </div>
                <div class="comparison-label">200 Epochs</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2_content/training_progression/lego_400_epoch_render.png" alt="400 Epochs">
                </div>
                <div class="comparison-label">400 Epochs</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2_content/training_progression/lego_800_epoch_render.png" alt="800 Epochs">
                </div>
                <div class="comparison-label">800 Epochs</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2_content/training_progression/lego_1500_epoch_render.png" alt="1500 Epochs">
                </div>
                <div class="comparison-label">1500 Epochs</div>
            </div>
        </div>

        <div class="large-comparison">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2_content/training_progression/lego_ground_truth.png" alt="Ground Truth">
                </div>
                <div class="comparison-label">Ground Truth</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2_content/training_progression/lego_final_render.png" alt="Final">
                </div>
                <div class="comparison-label">Final Result (2000 Epochs)</div>
            </div>
        </div>

        <h3>Training Metrics</h3>
        <div style="text-align: center; margin: 40px 0;">
            <div class="image-container">
                <img src="proj4/part2_content/lego_loss_psnr.png" alt="Lego Training Curve">
            </div>
            <div class="comparison-label">Training Loss and PSNR Curve</div>
        </div>


        <h3>Spherical Rendering</h3>
        <p>Spherical rendering of the Lego scene:</p>

        <div class="video-container">
            <video width="600" loop autoplay muted>
                <source src="proj4/part2_content/lego_nerf_video_circular_orbit.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </div>
        <div style="text-align: center; color: #808080; margin-top: 10px;">
            Lego NeRF - Spherical Rendering
        </div>


        <h3 id="part2_6">Part 2.6: Training NeRF on Own Data</h3>

        <p>
            Using the dataset I created in Part 0, I trained a NeRF on my own captured object. This involved 
            adapting the network hyperparameters for real-world data, adjusting the near/far sampling bounds, 
            and fine-tuning the training process to handle the challenges of real camera data compared to the 
            synthetic Lego scene.
        </p>

        <h3>Hyperparameters for Real Data</h3>
        <div class="algorithm-box">
            <h4>Training Configuration:</h4>
            <ul>
                <li><strong>Near/Far Bounds:</strong> $z_{\text{near}}=0.02$, $z_{\text{far}}=0.5$ for close-up object capture</li>
                <li><strong>Camera Intrinsics:</strong> Used actual calibrated K matrix from ArUco calibration</li>
                <li><strong>Samples per Ray:</strong> 64 samples with denser sampling due to smaller depth range</li>
                <li><strong>Learning Rate:</strong> $5 \times 10^{-4}$ with Adam optimizer</li>
                <li><strong>Training Duration:</strong> 10,000 epochs for proper convergence</li>
                <li><strong>Batch Size:</strong> 10,000 rays per iteration</li>
            </ul>
        </div>


        <h3>Training Progression</h3>
        <p>Training progression showing the NeRF learning to represent my captured object. We can observe significant improvements in fine details as training progresses - the harmonium keys become increasingly well-defined and the yellow holes on the top near the ArUco tag become more visible and accurately rendered:</p>

        <div class="training-progression">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2.6_content/intermediate/vaja_2000_epochs.png" alt="2000 Epochs">
                </div>
                <div class="comparison-label">2000 Epochs</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2.6_content/intermediate/vaja_4000_epochs.png" alt="4000 Epochs">
                </div>
                <div class="comparison-label">4000 Epochs</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2.6_content/intermediate/vaja_6000_epochs.png" alt="6000 Epochs">
                </div>
                <div class="comparison-label">6000 Epochs</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2.6_content/intermediate/vaja_8000_epochs.png" alt="8000 Epochs">
                </div>
                <div class="comparison-label">8000 Epochs</div>
            </div>
        </div>

        <div class="large-comparison">
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2.6_content/intermediate/vaja_ground_truth.png" alt="Ground Truth">
                </div>
                <div class="comparison-label">Ground Truth</div>
            </div>
            <div class="comparison-item">
                <div class="image-container">
                    <img src="proj4/part2.6_content/intermediate/vaja_final_epochs.png" alt="Final">
                </div>
                <div class="comparison-label">Final Result</div>
            </div>
        </div>

        <h3>Training Metrics</h3>
        <div style="text-align: center; margin: 40px 0;">
            <div class="image-container">
                <img src="proj4/part2.6_content/vaja_psnr_loss.png" alt="Own Data Training Curve">
            </div>
            <div class="comparison-label">Training Loss and PSNR Curve for Own Data</div>
        </div>

        <h3>Spherical Rendering</h3>
        <p>Circular orbit rendering of my captured object:</p>

        <div class="video-container">
            <video width="600" loop autoplay muted>
                <source src="proj4/part2.6_content/vaja_nerf_video_circular_orbit.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </div>
        <div style="text-align: center; color: #808080; margin-top: 10px;">
            Own Data NeRF - Circular Rendering
        </div>


        <div style="text-align: center; color: #606060; margin-top: 80px; padding: 40px 0; border-top: 1px solid #2a2a2a;">
            © 2025 Sukhamrit Singh. All rights reserved.
        </div>
    </div>
</body>
</html>